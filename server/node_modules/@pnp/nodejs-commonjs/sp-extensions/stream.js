"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.StreamParser = void 0;
var tslib_1 = require("tslib");
var common_1 = require("@pnp/common-commonjs");
var odata_1 = require("@pnp/odata-commonjs");
var index_js_1 = require("@pnp/sp-commonjs/files/index.js");
var sp_1 = require("@pnp/sp-commonjs");
var StreamParser = /** @class */ (function (_super) {
    (0, tslib_1.__extends)(StreamParser, _super);
    function StreamParser() {
        return _super !== null && _super.apply(this, arguments) || this;
    }
    StreamParser.prototype.parseImpl = function (r, resolve) {
        resolve({ body: r.body, knownLength: parseInt(r.headers.get("content-length"), 10) });
    };
    return StreamParser;
}(odata_1.ODataParser));
exports.StreamParser = StreamParser;
(0, odata_1.extendFactory)(index_js_1.File, {
    getStream: function () {
        return this.clone(index_js_1.File, "$value", false).usingParser(new StreamParser())((0, odata_1.headers)({ "binaryStringResponseBody": "true" }));
    },
    /**
     * Sets the contents of a file using a chunked upload approach. Not supported in batching.
     *
     * @param stream The file to upload (as readable stream)
     * @param progress A callback function which can be used to track the progress of the upload
     * @param chunkSize The size of each file chunks, in bytes (default: 10485760)
     */
    setStreamContentChunked: function (stream, progress) {
        return (0, tslib_1.__awaiter)(this, void 0, void 0, function () {
            var uploadId, blockNumber, promise;
            var _this = this;
            return (0, tslib_1.__generator)(this, function (_a) {
                if (!(0, common_1.isFunc)(progress)) {
                    progress = function () { return null; };
                }
                uploadId = (0, common_1.getGUID)();
                blockNumber = -1;
                promise = Promise.resolve(0);
                return [2 /*return*/, new Promise(function (resolve) {
                        stream.on("data", function (chunk) {
                            blockNumber += 1;
                            if (blockNumber === 0) {
                                promise = promise.then(function () {
                                    progress({ uploadId: uploadId, blockNumber: blockNumber, chunkSize: chunk.length, currentPointer: 0, fileSize: -1, stage: "starting", totalBlocks: -1 });
                                    return (0, index_js_1.File)(_this).startUpload(uploadId, chunk);
                                });
                            }
                            else {
                                promise = promise.then(function (cp) {
                                    progress({ uploadId: uploadId, blockNumber: blockNumber, chunkSize: chunk.length, currentPointer: cp, fileSize: -1, stage: "continue", totalBlocks: -1 });
                                    return (0, index_js_1.File)(_this).continueUpload(uploadId, cp, chunk);
                                });
                            }
                        });
                        stream.on("end", function () { return (0, tslib_1.__awaiter)(_this, void 0, void 0, function () {
                            var _this = this;
                            return (0, tslib_1.__generator)(this, function (_a) {
                                progress({ uploadId: uploadId, blockNumber: blockNumber, chunkSize: -1, currentPointer: -1, fileSize: -1, stage: "finishing", totalBlocks: -1 });
                                promise.then(function (cp) { return resolve((0, index_js_1.File)(_this).finishUpload(uploadId, cp, Buffer.from([]))); });
                                return [2 /*return*/];
                            });
                        }); });
                    })];
            });
        });
    },
});
(0, odata_1.extendFactory)(index_js_1.Files, {
    /**
     * Uploads a file. Not supported for batching
     *
     * @param url The folder-relative url of the file
     * @param content The Blob file content or File readable stream to add
     * @param progress A callback function which can be used to track the progress of the upload
     * @param shouldOverWrite Should a file with the same name in the same location be overwritten? (default: true)
     * @param chunkSize The size of each file slice, in bytes (default: 10485760)
     * @returns The new File and the raw response.
     */
    // @tag("fis.addChunked")
    addChunked: function (url, content, progress, shouldOverWrite, chunkSize) {
        if (shouldOverWrite === void 0) { shouldOverWrite = true; }
        if (chunkSize === void 0) { chunkSize = 10485760; }
        return (0, tslib_1.__awaiter)(this, void 0, void 0, function () {
            var response, odataUrl, file;
            return (0, tslib_1.__generator)(this, function (_a) {
                switch (_a.label) {
                    case 0: return [4 /*yield*/, (0, sp_1.spPost)(this.clone(index_js_1.Files, "add(overwrite=" + shouldOverWrite + ",url='" + (0, sp_1.escapeQueryStrValue)(url) + "')", false))];
                    case 1:
                        response = _a.sent();
                        odataUrl = (0, sp_1.odataUrlFrom)(response);
                        if (!(0, common_1.stringIsNullOrEmpty)(odataUrl) && /%27/i.test(odataUrl)) {
                            odataUrl = odataUrl.replace(/%27/ig, "''");
                        }
                        file = this.clone(index_js_1.File);
                        file.data.url = odataUrl;
                        if ("function" === typeof content.read) {
                            return [2 /*return*/, file.setStreamContentChunked(content, progress, chunkSize)];
                        }
                        return [2 /*return*/, file.setContentChunked(content, progress, chunkSize)];
                }
            });
        });
    },
});
//# sourceMappingURL=stream.js.map